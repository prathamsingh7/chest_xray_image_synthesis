# Leveraging GANS for Chest X-Ray image synthesis

## Keywords: 
Chest X-ray image, Synthetic data generation, Generative Adversarial Networks (GANs), Auxiliary Classifier GAN (ACGAN), Imbalanced dataset, Auxiliary Classifier Wasserstein GAN (ACWGAN)

## Abstract: 
In the last few years, Deep learning has emerged as a transformative tool in medical diagnostics offering advanced and reliable findings. Medical imaging plays a pivotal role in diagnostic tasks, yet the scarcity of labeled data and privacy concerns pose significant challenges for leveraging deep learning techniques in this domain. This research addresses the data scarcity issue in medical image analysis by encouraging class-conditioned image synthesis. Synthetic images, generated using Generative Adversarial Networks (GANs), enhance the development of deep-learning models for medical imaging tasks, benefiting patients and healthcare providers. For this purpose, we employ the Auxiliary Classifier GAN (ACGAN) framework which facilitates the generation of labeled images. Despite the promising capabilities of ACGAN, challenges persist, particularly in scenarios with imbalanced datasets. To solve this issue and improve overall image quality, we utilize the Auxiliary Classifier Wasserstein GAN (ACWGAN) approach. ACWGAN enhances the image quality while also ensuring that the generated images adequately represent minority classes, crucial for accurate diagnostic tasks. Through extensive experimentation and evaluation, we demonstrate the effectiveness of the ACWGAN approach in synthesizing high-quality, labeled chest X-ray images. Furthermore, we train a ResNet-based CNN model to showcase the importance of auxiliary classifiers in both ACGAN and ACWGAN frameworks for ensuring accurate classification of synthesized images. 

This research compares its result with the following paper: https://ieeexplore.ieee.org/document/10032429

## Objectives: 
1. Explore GANs for generating realistic chest X-ray images to overcome data scarcity in medical imaging.
2. Assess the effectiveness of ACGANs for producing labeled chest X-ray images crucial for classification tasks.

## Overview of GANs:
- GAN: 
GANs consist of two neural networks, a generator and a discriminator, which are trained simultaneously in a game-theoretic fashion. The generator learns to produce realistic samples from random noise, while the discriminator learns to differentiate between real samples from the dataset and fake samples generated by the generator. Through adversarial training, GANs can generate high-quality synthetic data that closely resemble real data distributions.
- WGAN: 
WGANs aim to address the instability and mode collapse issues commonly encountered during training with standard GANs. The key innovation of WGANs lies in the use of the Wasserstein distance, also known as the Earth Moverâ€™s distance, as a metric for measuring the discrepancy between the distributions of real and generated samples. By optimizing the Wasserstein distance instead of the Jensen-Shannon divergence used in traditional GANs, WGANs produce more stable training dynamics and generate higher-quality samples.
<p align="center">
  <img width="460" height="300" src="https://github.com/prathamsingh7/chest_xray_image_synthesis/blob/main/images/GAN_comparison.png">
</p>

- ACGAN: 
ACGANs enhance traditional GANs by incorporating an auxiliary classifier into the discriminator network, enabling the generation of conditional samples. In addition to distinguishing between real and fake samples, the discriminator in ACGANs also predicts the class labels of the samples, effectively guiding the generator to produce samples belonging to specific classes. This conditioning mechanism allows for the generation of labeled synthetic data, which is useful for tasks such as image-to-image translation and semi-supervised learning.
- ACWGAN: 
ACWGANs represent an advancement over ACGANs and WGANs, combining the benefits of both frameworks. Building upon the Wasserstein distance formulation of WGANs and the conditional generation capability of ACGANs, ACWGANs enable the synthesis of high-quality, labeled data with improved stability and fidelity. By incorporating auxiliary classifiers into the Wasserstein discriminator, ACWGANs produce conditional samples that not only closely match the target distribution but also adhere to the class labels specified during training.

<p align="center">
  <img width="460" height="300" src="https://github.com/prathamsingh7/chest_xray_image_synthesis/blob/main/images/Working_of_GAN.png">
</p>

## Methodology:
The proposed hypothesis follows utilizing an ACGAN to generate chest X-ray images with class labels, followed by the utilization of an ACWGAN to address the limitations of ACGAN and effectively synthesize high-quality and reliable chest X-ray images. Our hypothesis is based on the fact that ACGAN can enhance the generation of labeled chest X-ray images by conditioning the generator on class information. This approach aligns with previous research demonstrating the effectiveness of ACGAN in generating conditional samples. However, ACGAN may encounter challenges such as mode collapse and limited diversity in the generated samples. To address these shortcomings, we propose the use of ACWGAN, which combines the advantages of WGANs and ACGANs. By incorporating the Wasserstein distance metric, ACWGANs offer more stable training dynamics and improved sample diversity compared to traditional GAN formulations. Additionally, the inclusion of an auxiliary classifier in ACWGAN allows for the generation of labeled samples with enhanced stability and diversity, addressing the limitations of ACGAN. Therefore, we hypothesize that the integration of ACGAN and ACWGAN in our approach will result in the synthesis of high-quality chest X-ray images with accurate class labels and improved representation of minority classes, ultimately enhancing the performance of downstream classification models. We further hypothesize that training a ResNet18-based classifier on the synthesized chest X-ray images and evaluating its performance on real chest X-ray images will demonstrate the ability of the generated images to capture meaningful features relevant to disease classification. By testing the classifier on real images, we aim to assess the generalization ability of the model trained on synthesized data and evaluate its performance in a real-world scenario.

## Project Workflow
<p align="center">
  <img width="460" height="300" src="https://github.com/prathamsingh7/chest_xray_image_synthesis/blob/main/images/Project_workflow.png">
</p>